---
layout: about
title: About
permalink: /
subtitle: Machine Learning Researcher at Yandex Research

profile:
  align: right
  image: assets/img/profile.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>ML Research Residency, Yandex Research</p>
    <p>Moscow Institute of Physics and Technology (MIPT)</p>

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

# announcements:
#   enabled: true # includes a list of news items
#   scrollable: true # adds a vertical scroll bar if there are more than 3 news items
#   limit: 5 # leave blank to include all the news in the `_news` folder

# latest_posts:
#   enabled: true
#   scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
#   limit: 3 # leave blank to include all the blog posts
---

I am a Machine Learning Researcher at **Yandex Research** (ML Residency under Artem Babenko), working at the intersection of **efficient deep learning**, **theoretical optimization**, and **large-scale distributed systems**.

My research centers on **efficiency in all embodiments**: memory, time, communication, and theoretical guarantees. It began with foundational work on **stochastic variational inequalities** and **zero-order (gradient-free) optimization**, inspired by the pioneering framework of Alexander Beznosikov. This led to practical innovations like **memory-efficient LLM fine-tuning via zero-order methods**, reducing memory footprint by 50%—culminating in the development of **ZO-Library**, an open-source toolkit for zero-order optimization.

Parallel to this, I became fascinated by the **learning dynamics of Transformers**. In collaboration with Andrey Grabovoy, we are closing the theoretical gap in understanding how these models evolve during training, connecting empirical scaling laws to rigorous dynamical systems analysis. Ideas like **orthogonalization** and **Muon-style updates** emerge naturally in this pursuit.

My engineering experience at **Yandex (Personalization R&D)**—where I accelerated data pipelines 20× and improved ranking metrics—grounds my research in real-world constraints.

Today, these threads converge in my work on **asynchronous pipeline parallelism** and **multi-cluster learning**, where theoretical insight and systems engineering must co-evolve to scale AI responsibly.

<a href="/publications/">Publications</a> • <a href="/projects/">Projects</a> • <a href="https://github.com/modernTalker/ZO-Library">ZO-Library</a>